{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import skew, kurtosis as kurt, entropy as entr\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 128 # sampling frequency = 128 Hz\n",
    "bins = 10 # used in entropy calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_path):\n",
    "    file_path = Path(file_path) # ensure it is a path object\n",
    "\n",
    "    if not file_path.exists():\n",
    "        print(f\"❌ File not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with file_path.open(\"rb\") as f:\n",
    "            participant_data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "        # extract first 32 channels out of 40 and remove 3-sec pre-trial baseline from each channel\n",
    "        eeg_data = participant_data[\"data\"][:, :32, 3*sf:] # shape (40, 32, 63*sf - 3*sf) = (trials, channels, sample values)\n",
    "        labels = participant_data[\"labels\"][:, :2] # shape (40, 2) = (trials, [valence arousal])\n",
    "\n",
    "        return eeg_data, labels\n",
    "    \n",
    "    except (pickle.UnpicklingError, EOFError) as e:\n",
    "        print(f\"❌ Error loading pickle file: {file_path} -> {e}\")\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error while loading {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare labels for target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_focus_level(valence, arousal):\n",
    "    if valence >= 4.5 and arousal >= 4.5: # highly focused\n",
    "        return 1\n",
    "    else: # distracted\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(labels):\n",
    "    focus_label = np.array([calculate_focus_level(v, a) for v, a in labels])\n",
    "\n",
    "    return focus_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to extract bandpower and statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = {\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 12),\n",
    "    \"beta\": (12, 30),\n",
    "    \"gamma\": (30, 45)\n",
    "}\n",
    "\n",
    "def compute_bandpower(eeg_channel_arr, band_name):\n",
    "    range = bands[band_name]\n",
    "\n",
    "    # get array of freqs and corresponding power values\n",
    "    freqs, psd = welch(eeg_channel_arr, sf, nperseg=256)\n",
    "    \n",
    "    # choose freqs within the freq range\n",
    "    valid_indices = np.logical_and(freqs >= range[0], freqs < range[1])\n",
    "\n",
    "    # calculate mean of all the power values for one channel\n",
    "    return np.mean(psd[valid_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stat_features(eeg_channel_arr):\n",
    "    mean = np.mean(eeg_channel_arr)\n",
    "    std = np.std(eeg_channel_arr)\n",
    "    skewness = skew(eeg_channel_arr)\n",
    "    kurtosis = kurt(eeg_channel_arr)\n",
    "\n",
    "    hist, _ = np.histogram(eeg_channel_arr, bins=bins, density=True)\n",
    "    entropy = entr(hist)\n",
    "\n",
    "    return mean, std, skewness, kurtosis, entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create feature matrix for 1 participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(eeg_data):\n",
    "    feature_matrix = []\n",
    "\n",
    "    for trial in eeg_data:\n",
    "        trial_features = []\n",
    "\n",
    "        for channel in trial:\n",
    "            theta = compute_bandpower(channel, \"theta\")\n",
    "            alpha = compute_bandpower(channel, \"alpha\")\n",
    "            beta = compute_bandpower(channel, \"beta\")\n",
    "            gamma = compute_bandpower(channel, \"gamma\")\n",
    "\n",
    "            beta_alpha_ratio = beta / alpha\n",
    "\n",
    "            mean, std, skewness, kurtosis, entropy = compute_stat_features(channel)\n",
    "\n",
    "            channel_features = [theta, alpha, beta, gamma, beta_alpha_ratio, mean, std, skewness, kurtosis, entropy]\n",
    "\n",
    "            trial_features.extend(channel_features)\n",
    "\n",
    "        feature_matrix.append(trial_features)\n",
    "\n",
    "    return np.array(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a single featre matrix for all participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, focus_label = [], []\n",
    "\n",
    "folder_path = Path(\"..\")/\"eeg_emotion_data\" # folder containing .dat file for each participant\n",
    "\n",
    "for participant_file in folder_path.iterdir():\n",
    "    eeg_data, labels = load_file(participant_file)\n",
    "\n",
    "    if eeg_data is None or labels is None:\n",
    "        print(f\"⚠️ Skipping {participant_file}: Failed to load data\")\n",
    "        continue\n",
    "\n",
    "    focus_label.extend(prepare_labels(labels).tolist())\n",
    "\n",
    "    feature_matrix.append(create_feature_matrix(eeg_data))\n",
    "\n",
    "\n",
    "feature_matrix = np.concatenate(feature_matrix, axis=0)\n",
    "focus_label = np.array(focus_label).reshape(-1, 1) # convert labels into a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "feature_matrix = scalar.fit_transform(feature_matrix)\n",
    "\n",
    "# add labels column at the end of feature_matrix\n",
    "feature_matrix = np.hstack((feature_matrix, focus_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save the final matrix as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Theta\", \"Alpha\", \"Beta\", \"Gamma\", \"BetaAlpha\", \"Mean\", \"Std\", \"Skew\", \"Kurt\", \"Entropy\"]\n",
    "\n",
    "column_names = [f\"{feature}_{i+1}\" for i in range(32) for feature in features]\n",
    "column_names.append(\"Focus_Level\")\n",
    "\n",
    "df = pd.DataFrame(feature_matrix, columns=column_names)\n",
    "df.to_excel(\"../1280x321_features_binaryfocus.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
